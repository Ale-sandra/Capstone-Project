{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9428312d-4311-4925-a732-3cf0838d1b0e",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "Percorso = r\"C:\\Users\\aless\\Desktop\\PROGETTO FINALE - AGENZIA\\File annuali da visurare\\Visure completate\"\n",
    "\n",
    "file = pd.read_excel(r\"C:\\Users\\aless\\Desktop\\PROGETTO FINALE - AGENZIA\\File annuali da visurare\\Visure completate\\Mancati_rinnovi_2022_aggiornato.xlsx\")\n",
    "file\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88c227c1-b2ef-489d-8708-3f25082fd594",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "Percorso = r\"C:\\Users\\aless\\Desktop\\PROGETTO FINALE - AGENZIA\\File annuali da visurare\\Visure completate\"\n",
    "file_path = os.path.join(Percorso, \"Mancati_rinnovi_2022_aggiornato.xlsx\")\n",
    "\n",
    "file = pd.read_excel(file_path)\n",
    "file\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "252dd558-a716-45b3-befe-9da13441cd01",
   "metadata": {},
   "outputs": [],
   "source": [
    "file.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19488b54-8543-4e89-9414-91d63b8f9a3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "file.columns = file.columns.str.strip()\n",
    "file[\"Visure Ania\"].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3b95662-fd20-45ab-845e-2a56836ff0b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "Valori_Ania_replace={'005 - GENERALI ITALIA':'Generali Italia',\n",
    "                     '057 - CATTOLICA':'Cattolica Assicurazioni',\n",
    "                     '671 - IPTIQ EMEA P&C':'Prima Assicurazioni',\n",
    "                     'Veicolo venduto':\"PASSAGGIO DI PROPRIETA'\" ,\n",
    "                     '151 - GROUPAMA ASS.NI':'Groupama Assicurazioni',\n",
    "                     '133 - HDI ASS.NI':'HDI Assicurazioni',\n",
    "                     '034 - UNIPOL':'Unipol Assicurazioni',\n",
    "                     '899 - GREAT LAKES INS.':'Prima Assicurazioni',\n",
    "                     '038 - VITTORIA ASS.NI':'Vittoria Assicurazioni',\n",
    "                     'RADIAZIONE PER DEMOLIZIONE':'RADIAZIONE PER DEMOLIZIONE',\n",
    "                     '864 - ZURICH INS EUROPE AG':'Zurich Italia Assicurazioni',\n",
    "                     '254 - ASSIMOCO':'Assimoco',\n",
    "                     \"PASSAGGIO DI PROPRIETA'\":\"PASSAGGIO DI PROPRIETA'\",\n",
    "                     'ALTRI CASI':\"NAN\",\n",
    "                     '003 - ALLIANZ':'Allianz',\n",
    "                     '970 - IPTIQ EMEA P&C':'Prima Assicurazioni',\n",
    "                     '911 - AECS - ADMIRAL':'Admiral',\n",
    "                     '600 - SOGESSUR S.A.':'Soggesur',\n",
    "                     '419 - INTESA SANPAOLO':'Intesa San Paolo Assicurazioni',\n",
    "                     '429 - TUA ASS.NI':'TUA Assicurazioni',\n",
    "                     '486 - BENE ASS.Soc.Benefit':'Bene Assicurazioni',\n",
    "                     '035 - SOC. REALE MUTUA':'Reale Mutua',\n",
    "                     'NAN':'NAN',\n",
    "                     '417 - ARCA ASS.NI':'Arca Assicurazioni',\n",
    "                     'CAMBIO DI RESIDENZA':'NAN',\n",
    "                     '032 - SARA ASS.NI':'Sara Assicurazioni',\n",
    "                     '139 - ALLIANZ DIRECT':'Allianz Direct',\n",
    "                     '416 - LINEAR ASSICURAZIONI':'Linear Assicurazioni',\n",
    "                     'RADIAZIONE PER ESPORTAZIONE IN ALTRO PAESE UE':'RADIAZIONE PER ESPORTAZIONE IN ALTRO PAESE',\n",
    "                     '014 - AXA ASS.NI':'AXA Assicurazioni',\n",
    "                     '198 - ZURICH INSURANCE':'Zurich Italia Assicurazioni',\n",
    "                     \"CAMBIO DESTINAZIONE E PASS PROPRIETA'\":\"PASSAGGIO DI PROPRIETA'\",\n",
    "                     '432 - VERTI ASSICURAZIONI':'Verti Assicurazioni',\n",
    "                     '086 - HDI ITALIA S.p.A.':'HDI Assicurazioni',\n",
    "                     '474 - NOBIS ASS.NI':'Nobis Assicurazioni',\n",
    "                     '922 - VIA VERSICHERUNG AG':'VHV Assicurazioni'\n",
    "    \n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ec24263-f500-4b36-88ea-30f2a64c782d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#troviamo i valori distinti della colonna Visure Ania\n",
    "import pandas as pd\n",
    "\n",
    "anni = [2025, 2024, 2023, 2022, 2021, 2020]\n",
    "Percorso = r\"C:\\Users\\aless\\Desktop\\PROGETTO FINALE - AGENZIA\\File annuali da visurare\\Visure completate\"\n",
    "\n",
    "valori_unici = set()\n",
    "\n",
    "for anno in anni:\n",
    "    path = fr\"{Percorso}\\Mancati_rinnovi_{anno}_aggiornato.xlsx\"\n",
    "    df = pd.read_excel(path)\n",
    "    colonna = df['Visure Ania'].dropna().astype(str).str.strip()\n",
    "    unici = set(colonna.unique())\n",
    "    print(f\"{anno}: {len(unici)} valori unici trovati\")\n",
    "    valori_unici.update(unici)\n",
    "\n",
    "print(\"\\n Elenco completo valori unici trovati su tutti gli anni:\")\n",
    "for v in sorted(valori_unici):\n",
    "    print(\"-\", v)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6eeeeb20-570c-457a-bb8a-80458c73cb58",
   "metadata": {},
   "outputs": [],
   "source": [
    "#mi creo un dizionario per normalizzare i nomi delle compagnie assicrative\n",
    "Valori_Ania_replace = {\n",
    "    '003 - ALLIANZ': 'Allianz',\n",
    "    '005 - GENERALI ITALIA': 'Generali Italia',\n",
    "    '014 - AXA ASS.NI': 'AXA Assicurazioni',\n",
    "    '019 - HELVETIA': 'Helvetia Assicurazioni',\n",
    "    '032 - SARA ASS.NI': 'Sara Assicurazioni',\n",
    "    '034 - UNIPOL': 'UnipolSai Assicurazioni',\n",
    "    '035 - SOC. REALE MUTUA': 'Reale Mutua Assicurazioni',\n",
    "    '038 - VITTORIA ASS.NI': 'Vittoria Assicurazioni',\n",
    "    '057 - CATTOLICA': 'Cattolica Assicurazioni',\n",
    "    '086 - HDI ITALIA S.p.A.': 'HDI Assicurazioni',\n",
    "    '133 - HDI ASS.NI': 'HDI Assicurazioni',\n",
    "    '139 - ALLIANZ DIRECT': 'Allianz Direct',\n",
    "    '151 - GROUPAMA ASS.NI': 'Groupama Assicurazioni',\n",
    "    '198 - ZURICH INSURANCE': 'Zurich Italia Assicurazioni',\n",
    "    '243 - AXA MPS ASS.NI DANNI': 'AXA MPS Assicurazioni Danni',\n",
    "    '247 - GENERTEL': 'Genertel Assicurazioni',\n",
    "    '254 - ASSIMOCO': 'Assimoco',\n",
    "    '346 - UNICREDIT ALLIANZ': 'Unicredit Allianz Assicurazioni',\n",
    "    '352 - ALLIANZ NEXT S.p.A.': 'Allianz Next',\n",
    "    '416 - LINEAR ASSICURAZIONI': 'Linear Assicurazioni',\n",
    "    '417 - ARCA ASS.NI': 'Arca Assicurazioni',\n",
    "    '419 - INTESA SANPAOLO': 'Intesa Sanpaolo Assicurazioni',\n",
    "    '429 - TUA ASS.NI': 'TUA Assicurazioni',\n",
    "    '432 - VERTI ASSICURAZIONI': 'Verti Assicurazioni',\n",
    "    '440 - QUIXA ASSICURAZIONI': 'Quixa Assicurazioni',\n",
    "    '474 - NOBIS ASS.NI': 'Nobis Assicurazioni',\n",
    "    '486 - BENE ASS.Soc.Benefit': 'Bene Assicurazioni',\n",
    "    '600 - SOGESSUR S.A.': 'Sogessur',\n",
    "    '667 - ADRIATIC': 'Adriatic Assicurazioni',\n",
    "    '671 - IPTIQ EMEA P&C': 'Prima Assicurazioni',\n",
    "    '864 - ZURICH INS EUROPE AG': 'Zurich Italia Assicurazioni',\n",
    "    '899 - GREAT LAKES INS.': 'Prima Assicurazioni',\n",
    "    '911 - AECS - ADMIRAL': 'Admiral',\n",
    "    '920 - INS. JSC DALLBOGG': 'Dallbogg Insurance',\n",
    "    '922 - VIA VERSICHERUNG AG': 'VHV Assicurazioni',\n",
    "    '924 - TRIGLAV D.D.': 'Triglav Assicurazioni',\n",
    "    '970 - IPTIQ EMEA P&C': 'Prima Assicurazioni',\n",
    "    '022 - ITAS MUTUA': 'ITAS Mutua Assicurazioni',\n",
    "    '955 - WAKAM': 'Wakam Assicurazioni',\n",
    "    'AGGIORNAMENTO DELLA CARTA DI CIRCOLAZIONE PER INTESTAZIONE TEMPORANEA': 'Passaggio di propriet√†',\n",
    "    'AGGIORNAMENTO DELLA CARTA DI CIRCOLAZIONE PER INTESTAZIONE TEMPORANEA A SOGGETTO DIVERSO DALL INTESTATARIO': 'Passaggio di propriet√†',\n",
    "    'INSTALLAZIONE GANCIO': 'Non determinante',\n",
    "    'INSTALLAZIONE IMPIANTO GPL': 'Non determinante',\n",
    "    'INSTALLAZIONE IMPIANTO METANO': 'Non determinante',\n",
    "    'Veicolo venduto': 'Passaggio di propriet√†',\n",
    "    'CAMBIO DESTINAZIONE E PASS PROPRIETA\\'': 'Passaggio di propriet√†',\n",
    "    'PASSAGGIO DI PROPRIETA\\'': 'Passaggio di propriet√†',\n",
    "    'RADIAZIONE PER DEMOLIZIONE': 'RADIAZIONE PER DEMOLIZIONE',\n",
    "    'RADIAZIONE PER ESPORTAZIONE IN ALTRO PAESE UE': 'RADIAZIONE PER ESPORTAZIONE IN ALTRO PAESE',\n",
    "    'CAMBIO DI RESIDENZA': 'Non determinante',\n",
    "    'FURTO O SMARRIMENTO': 'Non determinante',\n",
    "    'DETERIORAMENTO': 'Non determinante',\n",
    "    'ALTRI CASI': 'Non determinante',\n",
    "    'Nessun dettaglio in banca dati ANIA': 'Nessuna copertura trovata',\n",
    "    'NAN': 'Nessuna copertura trovata'\n",
    "}\n",
    "#convertiamo il set in lista per poterci lavorare\n",
    "valori_unici_lista = list(valori_unici)\n",
    "\n",
    "#applichiamo il dizionario di normalizzazione\n",
    "valori_normalizzati = [Valori_Ania_replace.get(v, v) for v in valori_unici_lista]\n",
    "\n",
    "#creiamo un dataframe per visualizzare subito cosa √® stato normalizzato\n",
    "df_valori = pd.DataFrame({\n",
    "    \"Valore_Originale\": valori_unici_lista,\n",
    "    \"Valore_Normalizzato\": valori_normalizzati\n",
    "})\n",
    "print(df_valori.sort_values(by=\"Valore_Originale\").head(20))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4aa3705-5301-45e7-a032-eaeff26a4261",
   "metadata": {},
   "outputs": [],
   "source": [
    "#andiamo a sostituire i valori normalizzati nei file (2021-2025)\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "anni = [2025, 2024, 2023, 2022, 2021, 2020]\n",
    "Percorso = r\"C:\\Users\\aless\\Desktop\\PROGETTO FINALE - AGENZIA\\File annuali da visurare\\Visure completate\"\n",
    "\n",
    "for anno in anni:\n",
    "    path = fr\"{Percorso}\\Mancati_rinnovi_{anno}_aggiornato.xlsx\"\n",
    "    print(f\"Pulizia file {anno}...\")\n",
    "    \n",
    "    df = pd.read_excel(path)\n",
    "    if \"Visure Ania\" in df.columns:\n",
    "        df[\"Visure Ania\"] = df[\"Visure Ania\"].replace(Valori_Ania_replace)\n",
    "    else:\n",
    "        print(f\"Colonna 'Visure Ania' non trovata in {anno}\")\n",
    "\n",
    "    output_clean = fr\"{Percorso}\\Mancati_rinnovi_{anno}_pulito.xlsx\"\n",
    "    df.to_excel(output_clean, index=False)\n",
    "    print(f\"File pulito salvato: {output_clean}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bde52deb-e4d4-4544-8615-cc99d4dce14f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#ricaviamo dal CF la data di nsacita dei clienti (mi serve per studiare l'et√† di chi si assicura online)\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "\n",
    "anni = [2025, 2024, 2023, 2022, 2021, 2020]\n",
    "Percorso = r\"C:\\Users\\aless\\Desktop\\PROGETTO FINALE - AGENZIA\\File annuali da visurare\\Visure completate\"\n",
    "\n",
    "# Mappa mesi codice fiscale\n",
    "mesi_cf = {\n",
    "    'A': 1, 'B': 2, 'C': 3, 'D': 4, 'E': 5, 'H': 6,\n",
    "    'L': 7, 'M': 8, 'P': 9, 'R': 10, 'S': 11, 'T': 12\n",
    "}\n",
    "\n",
    "def estrai_data_sesso(cf):\n",
    "    \"\"\"Ritorna data di nascita e sesso a partire dal codice fiscale.\"\"\"\n",
    "    if not isinstance(cf, str) or len(cf) < 11:\n",
    "        return pd.Series([None, None])\n",
    "    try:\n",
    "        anno = int(cf[6:8])\n",
    "        mese_lettera = cf[8].upper()\n",
    "        giorno = int(cf[9:11])\n",
    "        # Gestione secolo (post 1926 ‚Üí 1900, altrimenti 2000)\n",
    "        anno_completo = 1900 + anno if anno > 25 else 2000 + anno\n",
    "        # Sesso e giorno effettivo\n",
    "        if giorno > 40:\n",
    "            sesso = \"F\"\n",
    "            giorno -= 40\n",
    "        else:\n",
    "            sesso = \"M\"\n",
    "        mese = mesi_cf.get(mese_lettera, None)\n",
    "        # Crea la data completa\n",
    "        data_nascita = pd.to_datetime(f\"{giorno}-{mese}-{anno_completo}\", format=\"%d-%m-%Y\", errors=\"coerce\")\n",
    "        return pd.Series([data_nascita, sesso])\n",
    "    except Exception:\n",
    "        return pd.Series([None, None])\n",
    "\n",
    "\n",
    "#cicliamo\n",
    "for anno in anni:\n",
    "    path = fr\"{Percorso}\\Mancati_rinnovi_{anno}_pulito.xlsx\"\n",
    "    print(f\"\\n Caricamento file: {path}\")\n",
    "    df = pd.read_excel(path)\n",
    "\n",
    "    if \"Codice Fiscale\" in df.columns:\n",
    "        print(\" Estrazione data di nascita e sesso dal CF...\")\n",
    "        df[[\"Data_Nascita\", \"Sesso\"]] = df[\"Codice Fiscale\"].apply(estrai_data_sesso)\n",
    "\n",
    "        # Calcolo Et√† alla Scadenza\n",
    "        if \"Data Scadenza\" in df.columns:\n",
    "            df[\"Data Scadenza\"] = pd.to_datetime(df[\"Data Scadenza\"], errors='coerce', dayfirst=True)\n",
    "            df[\"Et√†_alla_Scadenza\"] = df[\"Data Scadenza\"].dt.year - df[\"Data_Nascita\"].dt.year\n",
    "        else:\n",
    "            df[\"Et√†_alla_Scadenza\"] = None\n",
    "\n",
    "        # Salvataggio\n",
    "        output_path = fr\"{Percorso}\\Mancati_rinnovi_{anno}_anagrafico.xlsx\"\n",
    "        df.to_excel(output_path, index=False)\n",
    "        print(f\" File salvato con colonne: Data_Nascita, Sesso, Et√†_alla_Scadenza ‚Üí {output_path}\")\n",
    "    else:\n",
    "        print(f\" Nessuna colonna 'Codice Fiscale' trovata per il file {anno}, salto.\")\n",
    "\n",
    "print(\"\\n Tutti i file elaborati!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d434cf3-2c24-4090-9621-5c3b45c20959",
   "metadata": {},
   "outputs": [],
   "source": [
    "#utilizziamo i dati trovati nella colonna Visura Ania per creare la tabella con i dati delle Compagnie assicrative\n",
    "import pandas as pd\n",
    "\n",
    "# Supponiamo di avere gi√† df_valori con:\n",
    "# - Valore_Originale (es. \"003 - ALLIANZ\")\n",
    "# - Valore_Normalizzato (es. \"Allianz\")\n",
    "\n",
    "# Dizionario del tipo di canale\n",
    "tipo_canale = {\n",
    "    \"Allianz Direct\": \"Online\",\n",
    "    \"Prima Assicurazioni\": \"Online\",\n",
    "    \"Verti Assicurazioni\": \"Online\",\n",
    "    \"Quixa Assicurazioni\": \"Online\",\n",
    "    \"Linear Assicurazioni\": \"Online\",\n",
    "    \"VHV Assicurazioni\": \"Online\",\n",
    "    \"Admiral\": \"Online\",\n",
    "\n",
    "    \"Genertel Assicurazioni\": \"Ibrido\",\n",
    "    \"Zurich Italia Assicurazioni\": \"Ibrido\",\n",
    "    \"AXA MPS Assicurazioni Danni\": \"Ibrido\",\n",
    "    \"TUA Assicurazioni\": \"Ibrido\",\n",
    "    \"HDI Assicurazioni\": \"Ibrido\",\n",
    "    \"Nobis Assicurazioni\": \"Ibrido\",\n",
    "    \"Bene Assicurazioni\": \"Ibrido\",\n",
    "    \"Sogessur Assicurazioni\": \"Ibrido\",\n",
    "    \"Arca Assicurazioni\": \"Ibrido\",\n",
    "    \"Assimoco Assicurazioni\": \"Ibrido\",\n",
    "\n",
    "    \"Generali Italia\": \"Tradizionale\",\n",
    "    \"Cattolica Assicurazioni\": \"Tradizionale\",\n",
    "    \"Groupama Assicurazioni\": \"Tradizionale\",\n",
    "    \"UnipolSai Assicurazioni\": \"Tradizionale\",\n",
    "    \"Vittoria Assicurazioni\": \"Tradizionale\",\n",
    "    \"Reale Mutua Assicurazioni\": \"Tradizionale\",\n",
    "    \"Allianz\": \"Tradizionale\",\n",
    "    \"AXA Assicurazioni\": \"Tradizionale\",\n",
    "    \"Sara Assicurazioni\": \"Tradizionale\",\n",
    "    \"Intesa Sanpaolo Assicurazioni\": \"Tradizionale\",\n",
    "    \"Helvetia Assicurazioni\": \"Tradizionale\",\n",
    "}\n",
    "\n",
    "# Estrai il codice compagnia dal valore originale \n",
    "# (es. \"003 - ALLIANZ\" ‚Üí \"003\")\n",
    "df_valori[\"Codice_Compagnia\"] = df_valori[\"Valore_Originale\"].str.extract(r\"^(\\d+)\", expand=False)\n",
    "\n",
    "# Aggiungi il tipo canale basandoti sul nome normalizzato\n",
    "df_valori[\"Tipo_canale\"] = df_valori[\"Valore_Normalizzato\"].map(tipo_canale)\n",
    "\n",
    "# Pulisci la tabella e rinomina le colonne \n",
    "df_compagnie = df_valori[[\"Codice_Compagnia\", \"Valore_Normalizzato\", \"Tipo_canale\"]].drop_duplicates()\n",
    "df_compagnie = df_compagnie.rename(columns={\"Valore_Normalizzato\": \"Nome_Compagnia\"})\n",
    "df_compagnie.insert(0, \"ID_Compagnia\", range(1, len(df_compagnie) + 1))\n",
    "\n",
    "# Visualizza risultato \n",
    "print(df_compagnie.head(20))\n",
    "\n",
    "# Salva la tabella per usarla nello star schema\n",
    "df_compagnie.to_excel(r\"C:\\Users\\aless\\Desktop\\PROGETTO FINALE - AGENZIA\\Compagnie_Assicurative.xlsx\", index=False)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed5932ce-5c4f-4e7b-b7b2-6849d5e84365",
   "metadata": {},
   "outputs": [],
   "source": [
    "#utilizziamo i dati trovati nella colonna Visura Ania per creare la tabella con i dati delle Compagnie assicrative\n",
    "import pandas as pd\n",
    "import os\n",
    "# Dizionario del tipo di canale\n",
    "tipo_canale = {\n",
    "    \"Allianz Direct\": \"Online\",\n",
    "    \"Prima Assicurazioni\": \"Online\",\n",
    "    \"Verti Assicurazioni\": \"Online\",\n",
    "    \"Quixa Assicurazioni\": \"Online\",\n",
    "    \"Linear Assicurazioni\": \"Online\",\n",
    "    \"VHV Assicurazioni\": \"Online\",\n",
    "    \"Admiral\": \"Online\",\n",
    "    \"Wakam Assicurazioni\": \"Online\",\n",
    "\n",
    "    \"Genertel Assicurazioni\": \"Ibrido\",\n",
    "    \"Zurich Italia Assicurazioni\": \"Ibrido\",\n",
    "    \"AXA MPS Assicurazioni Danni\": \"Ibrido\",\n",
    "    \"TUA Assicurazioni\": \"Ibrido\",\n",
    "    \"HDI Assicurazioni\": \"Ibrido\",\n",
    "    \"Nobis Assicurazioni\": \"Ibrido\",\n",
    "    \"Bene Assicurazioni\": \"Ibrido\",\n",
    "    \"Sogessur\": \"Ibrido\",\n",
    "    \"Arca Assicurazioni\": \"Ibrido\",\n",
    "    \"Assimoco\": \"Ibrido\",\n",
    "    \"Unicredit Allianz Assicurazioni\": \"Ibrido\",\n",
    "    \"Allianz Next\": \"Ibrido\",\n",
    "    \"Adriatic Assicurazioni\": \"Ibrido\",\n",
    "    \"Triglav Assicurazioni\": \"Ibrido\",\n",
    "    \"ITAS Mutua Assicurazioni\": \"Ibrido\",\n",
    "\n",
    "    \"Generali Italia\": \"Tradizionale\",\n",
    "    \"Cattolica Assicurazioni\": \"Tradizionale\",\n",
    "    \"Groupama Assicurazioni\": \"Tradizionale\",\n",
    "    \"UnipolSai Assicurazioni\": \"Tradizionale\",\n",
    "    \"Vittoria Assicurazioni\": \"Tradizionale\",\n",
    "    \"Reale Mutua Assicurazioni\": \"Tradizionale\",\n",
    "    \"Allianz\": \"Tradizionale\",\n",
    "    \"AXA Assicurazioni\": \"Tradizionale\",\n",
    "    \"Sara Assicurazioni\": \"Tradizionale\",\n",
    "    \"Intesa Sanpaolo Assicurazioni\": \"Tradizionale\",\n",
    "    \"Helvetia Assicurazioni\": \"Tradizionale\",\n",
    "}\n",
    "\n",
    "\n",
    "#estraggo codice compagnia  dove presente\n",
    "df_valori[\"Codice_Ania\"] = df_valori[\"Valore_Originale\"].str.extract(r\"^(\\d+)\", expand=False)\n",
    "\n",
    "#tengo solo le righe che hanno effettivamente un codice (le altre non sono compagnie)\n",
    "df_filtrato = df_valori[df_valori[\"Codice_Ania\"].notna()].copy()\n",
    "\n",
    "#aggiungo il tipo canale\n",
    "df_filtrato[\"Tipo_canale\"] = df_filtrato[\"Valore_Normalizzato\"].map(tipo_canale)\n",
    "\n",
    "#creiamo la tabella\n",
    "df_compagnie = (df_filtrato[[\"Codice_Ania\", \"Valore_Normalizzato\", \"Tipo_canale\"]].drop_duplicates().rename(columns={\"Valore_Normalizzato\": \"Nome_Compagnia\"}).sort_values(by=\"Codice_Ania\").reset_index(drop=True))\n",
    "\n",
    "#aggiungo una chiave surrogata progressiva\n",
    "df_compagnie.insert(0, \"ID_Compagnia\", range(1, len(df_compagnie) + 1))\n",
    "\n",
    "#salviamo\n",
    "df_compagnie.to_excel(r\"C:\\Users\\aless\\Desktop\\PROGETTO FINALE - AGENZIA\\Dataset\\Compagnie_Assicurative.xlsx\", index=False)\n",
    "\n",
    "print(df_compagnie.head(10))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9df3ab88-cb00-4ff2-b1c7-cf635d6588c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#dal dataset principale ci prendiamo i nomi dei subagenti oer creare la tabella Produttori\n",
    "import pandas as pd\n",
    "\n",
    "# Percorso del file unico\n",
    "file_path = r\"C:\\Users\\aless\\Desktop\\PROGETTO FINALE - AGENZIA\\DATASET RINNOVI.xlsx\"\n",
    "\n",
    "# Legge tutti i fogli (uno per anno)\n",
    "all_sheets = pd.read_excel(file_path, sheet_name=None)\n",
    "\n",
    "# Set per contenere i valori unici globali\n",
    "valori_unici = set()\n",
    "\n",
    "\n",
    "for nome_foglio, df in all_sheets.items():\n",
    "    if \"Sub Agenzia\" not in df.columns:\n",
    "        print(f\"Il foglio '{nome_foglio}' non contiene la colonna 'Sub Agenzia'.\")\n",
    "        continue\n",
    "\n",
    "    colonna = df[\"Sub Agenzia\"].dropna().astype(str).str.strip()\n",
    "    unici = set(colonna.unique())\n",
    "\n",
    "    print(f\"Foglio '{nome_foglio}': {len(unici)} subagenzie trovate\")\n",
    "    valori_unici.update(unici)\n",
    "\n",
    "print(\"\\n Elenco completo subagenzie trovate in tutti i fogli:\")\n",
    "for v in sorted(valori_unici):\n",
    "    print(\"-\", v)\n",
    "\n",
    "print(f\"\\n Totale subagenzie complessive: {len(valori_unici)}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f28d3966-f93c-4b6a-b175-a2f87418fb3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# creiamo la tabella con i codici reali e sostituiamo per privacy i nomi dei subagenti\n",
    "df = pd.DataFrame(sorted(valori_unici), columns=[\"Sub Agenzia\"])\n",
    "\n",
    "#divido codice e nome (se presenti)\n",
    "df[[\"Codice_Produttore\", \"Nome_Produttore\"]] = df[\"Sub Agenzia\"].str.extract(r\"^(\\d+)\\s*(.*)$\")\n",
    "\n",
    "# Gestisco il caso \"AGENZIA\"\n",
    "mask_agenzia = df[\"Sub Agenzia\"].str.upper() == \"AGENZIA\"\n",
    "df.loc[mask_agenzia, \"Codice_Produttore\"] = \"100\"\n",
    "df.loc[mask_agenzia, \"Nome_Produttore\"] = \"Agenzia Principale\"\n",
    "\n",
    "# Converto il codice in numerico\n",
    "df[\"Codice_Produttore\"] = df[\"Codice_Produttore\"].astype(int)\n",
    "\n",
    "#Nomi fittizi\n",
    "nomi_produttori = {\n",
    "    100: \"Agenzia Principale\",\n",
    "    101: \"Alpha Consulting\",\n",
    "    102: \"Beta Insurance\",\n",
    "    103: \"Gamma Broker\",\n",
    "    104: \"Delta Assicurazioni\",\n",
    "    110: \"Epsilon Group\",\n",
    "    200: \"Zeta Services\"\n",
    "}\n",
    "\n",
    "# Localit√† reali\n",
    "localita_produttori = {\n",
    "    100: \"Rossano\",\n",
    "    101: \"Cariati\",\n",
    "    102: \"Corigliano\",\n",
    "    103: \"Cassano Allo Ionio\",\n",
    "    104: \"San Giorgio Albanese\",\n",
    "    110: \"Trebisacce\",\n",
    "    200: \"Terranova da Sibari\"\n",
    "}\n",
    "\n",
    "# Applica nomi e localit√†\n",
    "df[\"Nome_Produttore\"] = df[\"Codice_Produttore\"].map(nomi_produttori)\n",
    "df[\"Localit√†\"] = df[\"Codice_Produttore\"].map(localita_produttori)\n",
    "\n",
    "# Tieni solo le colonne utili e ordina per codice\n",
    "df = df[[\"Codice_Produttore\", \"Nome_Produttore\", \"Localit√†\"]].sort_values(\"Codice_Produttore\").reset_index(drop=True)\n",
    "\n",
    "# Salva \n",
    "output_path = r\"C:\\Users\\aless\\Desktop\\PROGETTO FINALE - AGENZIA\\Dataset\\Rete_Agenziale.xlsx\"\n",
    "df.to_excel(output_path, index=False)\n",
    "\n",
    "print(f\"\\n Tabella Produttori creata: {output_path}\")\n",
    "print(df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b62e006d-648f-4510-86b8-efea685a1841",
   "metadata": {},
   "outputs": [],
   "source": [
    "#stessa cosa facciamo per i prodotti\n",
    "import pandas as pd\n",
    "\n",
    "# Percorso del file unico\n",
    "file_path = r\"C:\\Users\\aless\\Desktop\\PROGETTO FINALE - AGENZIA\\DATASET RINNOVI.xlsx\"\n",
    "\n",
    "# Legge tutti i fogli (uno per anno)\n",
    "all_sheets = pd.read_excel(file_path, sheet_name=None)\n",
    "\n",
    "# Set per contenere i valori unici globali\n",
    "valori_unici = set()\n",
    "\n",
    "\n",
    "for nome_foglio, df in all_sheets.items():\n",
    "    if \"Nome Prodotto Attuale\" not in df.columns:\n",
    "        print(f\" Il foglio '{nome_foglio}' non contiene la colonna 'Nome Prodotto Attuale'.\")\n",
    "        continue\n",
    "\n",
    "    colonna = df[\"Nome Prodotto Attuale\"].dropna().astype(str).str.strip()\n",
    "    unici = set(colonna.unique())\n",
    "\n",
    "    print(f\"üìÑ Foglio '{nome_foglio}': {len(unici)} prodotti\")\n",
    "    valori_unici.update(unici)\n",
    "\n",
    "\n",
    "print(\"\\n Elenco completo prodotti in tutti i fogli:\")\n",
    "for v in sorted(valori_unici):\n",
    "    print(\"-\", v)\n",
    "\n",
    "print(f\"\\n Totale prodotti: {len(valori_unici)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fa2aea0-5a18-4d9f-939c-1b85ce1d62c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#creiamo la tabella cin le edizioni dei set informativi\n",
    "import pandas as pd\n",
    "\n",
    "# Percorso del file unico\n",
    "file_path = r\"C:\\Users\\aless\\Desktop\\PROGETTO FINALE - AGENZIA\\DATASET RINNOVI.xlsx\"\n",
    "\n",
    "# Legge tutti i fogli (uno per anno)\n",
    "all_sheets = pd.read_excel(file_path, sheet_name=None)\n",
    "\n",
    "# Dizionario set informativo\n",
    "Set_Informativo = {\n",
    "    \"Ad hoc unico\": \"ed. 10/2009\",\n",
    "    \"Autocontrollo 2.0\": \"ed. 10/2021\",\n",
    "    \"Autocontrollo Autovetture 2022\": \"ed. 06/2025\",\n",
    "    \"Autocontrollo2-0\": \"ed. 04/2018\",\n",
    "    \"Groupama Auto\": \"ed. 04/2018\",\n",
    "    \"Guidamica - Veicoli\": \"ed. 06/2025\",\n",
    "    \"Guidamica Autovetture 2022\": \"ed. 06/2025\",\n",
    "    \"Guidamica--Veicoli\": \"ed. 10/2021\"\n",
    "}\n",
    "\n",
    "# Lista per accumulare i dati prodotto-codice-edizione\n",
    "prodotti_list = []\n",
    "\n",
    "# Ciclo\n",
    "for nome_foglio, df in all_sheets.items():\n",
    "    # Controllo colonne necessarie\n",
    "    if \"Nome Prodotto Attuale\" not in df.columns or \"Codice Prodotto Attuale\" not in df.columns:\n",
    "        print(f\" Il foglio '{nome_foglio}' non contiene entrambe le colonne richieste.\")\n",
    "        continue\n",
    "\n",
    "    # Pulizia di base\n",
    "    df['Nome Prodotto Attuale'] = df['Nome Prodotto Attuale'].astype(str).str.strip()\n",
    "    df['Codice Prodotto Attuale'] = df['Codice Prodotto Attuale'].astype(str).str.strip()\n",
    "\n",
    "    #  Aggiunge colonna ‚ÄúUltima Edizione Set Informativo‚Äù\n",
    "    df['Ultima Edizione Set Informativo'] = (df['Nome Prodotto Attuale'].map(Set_Informativo).fillna(\"ND\"))\n",
    "\n",
    "    # Seleziono solo colonne d‚Äôinteresse\n",
    "    prodotti_list.append(df[['Codice Prodotto Attuale', 'Nome Prodotto Attuale', 'Ultima Edizione Set Informativo']])\n",
    "\n",
    "    print(f\" Foglio '{nome_foglio}': {df['Nome Prodotto Attuale'].nunique()} prodotti unici\")\n",
    "\n",
    "# Uniamo tutto\n",
    "prodotti_df = pd.concat(prodotti_list, ignore_index=True).drop_duplicates(subset=['Codice Prodotto Attuale', 'Nome Prodotto Attuale'])\n",
    "\n",
    "# Ordina per codice\n",
    "prodotti_df = prodotti_df.sort_values(by='Codice Prodotto Attuale').reset_index(drop=True)\n",
    "# Aggiungi ID univoco\n",
    "prodotti_df.insert(0, 'ID_Prodotto', range(1, len(prodotti_df) + 1))\n",
    "\n",
    "\n",
    "\n",
    "output_path = r\"C:\\Users\\aless\\Desktop\\PROGETTO FINALE - AGENZIA\\Dataset\\Elenco_Prodotti_Auto.xlsx\"\n",
    "prodotti_df.to_excel(output_path, index=False)\n",
    "\n",
    "print(\"\\n Tabella 'Prodotti' creata con successo!\")\n",
    "print(f\" Salvata in: {output_path}\")\n",
    "print(f\"Totale prodotti unici: {len(prodotti_df)}\")\n",
    "\n",
    "# Mostra anteprima\n",
    "print(\"\\n Prime righe della tabella Prodotti:\")\n",
    "print(prodotti_df.head(10))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de8bd818-2b70-4dbe-b64d-adc9a4fdc461",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Percorso del file unico\n",
    "file_path = r\"C:\\Users\\aless\\Desktop\\PROGETTO FINALE - AGENZIA\\DATASET RINNOVI.xlsx\"\n",
    "\n",
    "# Legge tutti i fogli (uno per anno)\n",
    "all_sheets = pd.read_excel(file_path, sheet_name=None)\n",
    "\n",
    "# Set per contenere i valori unici globali\n",
    "subagenzie_uniche = set()\n",
    "produttori_unici = set()\n",
    "\n",
    "\n",
    "for nome_foglio, df in all_sheets.items():\n",
    "\n",
    "    # --- SUBAGENZIE ---\n",
    "    if \"Sub Agenzia\" in df.columns:\n",
    "        col_sub = df[\"Sub Agenzia\"].dropna().astype(str).str.strip()\n",
    "        unici_sub = set(col_sub.unique())\n",
    "        subagenzie_uniche.update(unici_sub)\n",
    "        print(f\" Foglio '{nome_foglio}': {len(unici_sub)} subagenzie trovate\")\n",
    "    else:\n",
    "        print(f\" Il foglio '{nome_foglio}' non contiene la colonna 'Sub Agenzia'.\")\n",
    "\n",
    "    # --- PRODUTTORI ---\n",
    "    if \"Produttore\" in df.columns:\n",
    "        col_prod = df[\"Produttore\"].dropna().astype(str).str.strip()\n",
    "        unici_prod = set(col_prod.unique())\n",
    "        produttori_unici.update(unici_prod)\n",
    "        print(f\" Foglio '{nome_foglio}': {len(unici_prod)} produttori trovati\")\n",
    "    else:\n",
    "        print(f\" Il foglio '{nome_foglio}' non contiene la colonna 'Produttore'.\")\n",
    "\n",
    "\n",
    "print(\"\\n Elenco completo SUBAGENZIE trovate:\")\n",
    "for s in sorted(subagenzie_uniche):\n",
    "    print(\"-\", s)\n",
    "print(f\"\\n Totale subagenzie complessive: {len(subagenzie_uniche)}\")\n",
    "\n",
    "print(\"\\n Elenco completo PRODUTTORI trovati:\")\n",
    "for p in sorted(produttori_unici):\n",
    "    print(\"-\", p)\n",
    "print(f\"\\n Totale produttori complessivi: {len(produttori_unici)}\")\n",
    "\n",
    "\n",
    "output_path = r\"C:\\Users\\aless\\Desktop\\PROGETTO FINALE - AGENZIA\\Dataset\\Rete_Agenzia.xlsx\"\n",
    "df_sub = pd.DataFrame(sorted(subagenzie_uniche), columns=[\"Sub Agenzia\"])\n",
    "df_prod = pd.DataFrame(sorted(produttori_unici), columns=[\"Produttore\"])\n",
    "\n",
    "with pd.ExcelWriter(r\"C:\\Users\\aless\\Desktop\\PROGETTO FINALE - AGENZIA\\Dataset\\Rete_Agenzia.xlsx\") as writer:\n",
    "    df_sub.to_excel(writer, sheet_name=\"Subagenzie\", index=False)\n",
    "    df_prod.to_excel(writer, sheet_name=\"Produttori\", index=False)\n",
    "\n",
    "with pd.ExcelWriter(output_path) as writer:\n",
    "    df_sub.to_excel(writer, sheet_name=\"Subagenzie\", index=False)\n",
    "    df_prod.to_excel(writer, sheet_name=\"Produttori\", index=False)\n",
    "\n",
    "print(f\"\\n Tabella 'Rete_Agenzia.xlsx' esportata correttamente in:\\n{output_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e3fd4a3-10da-4383-9471-6d50662c3a65",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "\n",
    "file_path = r\"C:\\Users\\aless\\Desktop\\PROGETTO FINALE - AGENZIA\\DATASET RINNOVI.xlsx\"\n",
    "\n",
    "# Legge tutti i fogli (uno per anno)\n",
    "all_sheets = pd.read_excel(file_path, sheet_name=None)\n",
    "\n",
    "# Set per contenere i valori unici\n",
    "subagenzie_uniche = set()\n",
    "produttori_unici = set()\n",
    "\n",
    "\n",
    "for nome_foglio, df in all_sheets.items():\n",
    "    # SUBAGENZIA\n",
    "    if \"Sub Agenzia\" in df.columns:\n",
    "        col_sub = df[\"Sub Agenzia\"].dropna().astype(str).str.strip()\n",
    "        subagenzie_uniche.update(col_sub.unique())\n",
    "\n",
    "    # PRODUTTORE\n",
    "    if \"Produttore\" in df.columns:\n",
    "        col_prod = df[\"Produttore\"].dropna().astype(str).str.strip()\n",
    "        produttori_unici.update(col_prod.unique())\n",
    "\n",
    "\n",
    "df_sub = pd.DataFrame(sorted(subagenzie_uniche), columns=[\"Sub Agenzia\"])\n",
    "\n",
    "# Dividi codice e nome (se presenti)\n",
    "df_sub[[\"Codice_SubAgenzia\", \"Nome_SubAgenzia\"]] = df_sub[\"Sub Agenzia\"].str.extract(r\"^(\\d+)\\s*(.*)$\")\n",
    "\n",
    "# Gestisce il caso ‚ÄúAGENZIA‚Äù\n",
    "mask_agenzia = df_sub[\"Sub Agenzia\"].str.upper() == \"AGENZIA\"\n",
    "df_sub.loc[mask_agenzia, \"Codice_SubAgenzia\"] = \"100\"\n",
    "df_sub.loc[mask_agenzia, \"Nome_SubAgenzia\"] = \"Agenzia Principale\"\n",
    "\n",
    "# Converte il codice in numerico (dove possibile)\n",
    "df_sub[\"Codice_SubAgenzia\"] = pd.to_numeric(df_sub[\"Codice_SubAgenzia\"], errors=\"coerce\").fillna(999).astype(int)\n",
    "\n",
    "# Nomi fittizi SubAgenzie\n",
    "nomi_subagenzie = {\n",
    "    100: \"Agenzia Principale\",\n",
    "    101: \"Alpha Consulting\",\n",
    "    102: \"Beta Insurance\",\n",
    "    103: \"Gamma Broker\",\n",
    "    104: \"Delta Assicurazioni\",\n",
    "    110: \"Epsilon Group\",\n",
    "    200: \"Zeta Services\"\n",
    "}\n",
    "\n",
    "# Localit√† fittizie\n",
    "localita_subagenzie = {\n",
    "    100: \"Rossano\",\n",
    "    101: \"Cariati\",\n",
    "    102: \"Corigliano\",\n",
    "    103: \"Cassano Allo Ionio\",\n",
    "    104: \"San Giorgio Albanese\",\n",
    "    110: \"Trebisacce\",\n",
    "    200: \"Terranova da Sibari\"\n",
    "}\n",
    "\n",
    "# Applica mapping\n",
    "df_sub[\"Nome_SubAgenzia\"] = df_sub[\"Codice_SubAgenzia\"].map(nomi_subagenzie).fillna(df_sub[\"Nome_SubAgenzia\"])\n",
    "df_sub[\"Localit√†\"] = df_sub[\"Codice_SubAgenzia\"].map(localita_subagenzie).fillna(\"Da definire\")\n",
    "\n",
    "\n",
    "df_prod = pd.DataFrame(sorted(produttori_unici), columns=[\"Produttore_Reale\"])\n",
    "\n",
    "# Crea codici fittizi incrementali\n",
    "df_prod[\"Codice_Produttore\"] = range(1000, 1000 + len(df_prod))\n",
    "\n",
    "# üîπ Genera nomi fittizi coerenti (ricicla se ce ne sono pi√π di 20)\n",
    "nomi_fittizi = [\n",
    "    \"Mario Rossi\", \"Luca Bianchi\", \"Giulia Verdi\", \"Marco Neri\", \"Anna Russo\",\n",
    "    \"Claudia Gallo\", \"Francesco Greco\", \"Elena Romano\", \"Davide Fontana\", \"Sara Marino\",\n",
    "    \"Paolo De Luca\", \"Alessia Ferraro\", \"Giorgio Serra\", \"Simone Ricci\", \"Chiara Costa\",\n",
    "    \"Valentina Conti\"\n",
    "]\n",
    "df_prod[\"Nome_Produttore\"] = [nomi_fittizi[i % len(nomi_fittizi)] for i in range(len(df_prod))]\n",
    "\n",
    "#\n",
    "# Se non hai un legame 1:1 reale, facciamo una distribuzione fittizia\n",
    "df_sub = df_sub.sort_values(\"Codice_SubAgenzia\").reset_index(drop=True)\n",
    "df_prod = df_prod.sort_values(\"Codice_Produttore\").reset_index(drop=True)\n",
    "\n",
    "# Assegna i produttori ciclicamente alle subagenzie\n",
    "df_prod[\"Codice_SubAgenzia\"] = df_sub[\"Codice_SubAgenzia\"].tolist() * (len(df_prod) // len(df_sub)) + df_sub[\"Codice_SubAgenzia\"].tolist()[:len(df_prod) % len(df_sub)]\n",
    "\n",
    "# Merge per creare tabella completa\n",
    "df_rete = pd.merge(df_prod, df_sub, on=\"Codice_SubAgenzia\", how=\"left\")\n",
    "\n",
    "# Tieni solo le colonne utili\n",
    "df_rete = df_rete[[\n",
    "    \"Codice_SubAgenzia\", \"Nome_SubAgenzia\", \"Localit√†\",\n",
    "    \"Codice_Produttore\", \"Nome_Produttore\"\n",
    "]]\n",
    "\n",
    "\n",
    "output_path = r\"C:\\Users\\aless\\Desktop\\PROGETTO FINALE - AGENZIA\\Dataset\\Rete_Agenziale.xlsx\"\n",
    "df_rete.to_excel(output_path, index=False)\n",
    "\n",
    "print(f\"\\n Tabella Rete_Agenziale creata correttamente in:\\n{output_path}\\n\")\n",
    "print(\" Anteprima:\")\n",
    "print(df_rete.head(10))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31e3622f-ad0d-4483-a9bf-a480db528653",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "\n",
    "cartella_input = r\"C:\\Users\\aless\\Desktop\\PROGETTO FINALE - AGENZIA\\Dataset\\Movimenti per anno RCA\"\n",
    "\n",
    "\n",
    "mappa_produttori = {\n",
    "    \"VULCANO EUGENIO\": (\"Mario Rossi\", 1000),\n",
    "    \"FRANCOMANO DOMENICO\": (\"Luca Bianchi\", 1001),\n",
    "    \"FUSARO MARIA RITA\": (\"Giulia Verdi\", 1002),\n",
    "    \"ROMEO ANTONIO\": (\"Marco Neri\", 1003),\n",
    "    \"SCARAMUZZO ALFREDO\": (\"Paolo De Luca\", 1004),\n",
    "    \"CAMPANA ANTONIO\": (\"Claudio Gallo\", 1005),\n",
    "    \"GALZARANO LUIGI\": (\"Francesco Greco\", 1006),\n",
    "    \"LE PERA ELVIRA\": (\"Elena Romano\", 1007),\n",
    "    \"CARBONE GENNARO\": (\"Davide Fontana\", 1008),\n",
    "    \"AGENTE\": (\"Sara Marino\", 1009),\n",
    "    \"GRAZIANO VALERIA\": (\"Alessia Ferraro\", 1011),\n",
    "    \"DATTOLI GIANFRANCO\": (\"Giorgio Serra\", 1012),\n",
    "    \"COSTANTINI SILVIA ROSA\": (\"Simone Ricci\", 1013),\n",
    "    \"MADEO RACHELE\": (\"Simone Ricci\", 1013),\n",
    "    \"EX AGENZIA N097\": (\"Chiara Costa\", 1014),\n",
    "    \"PUGLIESE PIER LUIGI\": (\"Valentina Conti\", 1015),\n",
    "}\n",
    "\n",
    "\n",
    "mappa_prodotti = {\n",
    "    \"AD HOC UNICO\": \"A1\",\n",
    "    \"GROUPAMA AUTO\": \"A2\",\n",
    "    \"GUIDAMICA--VEICOLI\": \"A3\",\n",
    "    \"GUIDAMICA - VEICOLI\": \"A3\",\n",
    "    \"AUTOCONTROLLO2-0\": \"A4\",\n",
    "    \"AUTOCONTROLLO 2.0\": \"A4\",\n",
    "    \"GUIDAMICA AUTOVETTURE 2022\": \"A5\",\n",
    "    \"AUTOCONTROLLO AUTOVETTURE 2022\": \"A6\"\n",
    "}\n",
    "\n",
    "\n",
    "def elabora_file(percorso_file):\n",
    "    print(f\" Elaboro: {os.path.basename(percorso_file)}\")\n",
    "\n",
    "    df = pd.read_excel(percorso_file)\n",
    "\n",
    "    # Rimuove la colonna \"Sub Agenzia\" se presente\n",
    "    if \"Sub Agenzia\" in df.columns:\n",
    "        df.drop(columns=[\"Sub Agenzia\"], inplace=True)\n",
    "\n",
    "    # Normalizza i valori in maiuscolo per il matching\n",
    "    df[\"Produttore\"] = df[\"Produttore\"].astype(str).str.strip().str.upper()\n",
    "\n",
    "    # üîπ Replace diretto nella colonna \"Produttore\"\n",
    "    for reale, (fittizio, codice) in mappa_produttori.items():\n",
    "        mask = df[\"Produttore\"] == reale\n",
    "        df.loc[mask, \"Produttore\"] = fittizio\n",
    "        df.loc[mask, \"Codice_Produttore\"] = codice\n",
    "\n",
    "    # üîπ Applica la mappatura dei prodotti\n",
    "    if \"Codice Prodotto\" in df.columns:\n",
    "        df[\"ID_Prodotto\"] = df[\"Codice Prodotto\"].map(mappa_prodotti)\n",
    "\n",
    "    # üîπ Salva nella stessa cartella con \"_completo\"\n",
    "    nome_output = os.path.basename(percorso_file).replace(\".xlsx\", \"_completo.xlsx\")\n",
    "    percorso_output = os.path.join(cartella_input, nome_output)\n",
    "    df.to_excel(percorso_output, index=False)\n",
    "\n",
    "    print(f\" Salvato: {nome_output} ({len(df)} righe)\\n\")\n",
    "\n",
    "\n",
    "for file in os.listdir(cartella_input):\n",
    "    if file.startswith(\"Dettaglio_movimenti_RCA_\") and file.endswith(\".xlsx\") and \"_completo\" not in file:\n",
    "        elabora_file(os.path.join(cartella_input, file))\n",
    "\n",
    "print(\"\\n Tutti i file sono stati elaborati e salvati con suffisso '_completo'.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "181f7790-a79f-44b6-9a1a-afbe2a84fb02",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "\n",
    "cartella_input = r\"C:\\Users\\aless\\Desktop\\PROGETTO FINALE - AGENZIA\\Dataset\\Movimenti per anno RCA\"\n",
    "\n",
    "# Set per raccogliere le coppie uniche\n",
    "operazioni_uniche = set()\n",
    "\n",
    "\n",
    "for file in os.listdir(cartella_input):\n",
    "    if file.startswith(\"Dettaglio_movimenti_RCA_\") and file.endswith(\".xlsx\"):\n",
    "        percorso_file = os.path.join(cartella_input, file)\n",
    "        print(f\" Leggo: {os.path.basename(percorso_file)}\")\n",
    "\n",
    "        df = pd.read_excel(percorso_file, usecols=[\"Codice Operazione\", \"Descrizione Operazione\"])\n",
    "\n",
    "        # Rimuove righe vuote\n",
    "        df = df.dropna(subset=[\"Codice Operazione\", \"Descrizione Operazione\"])\n",
    "\n",
    "        # Aggiunge al set le coppie (Codice, Descrizione)\n",
    "        for _, row in df.iterrows():\n",
    "            coppia = (str(row[\"Codice Operazione\"]).strip(), str(row[\"Descrizione Operazione\"]).strip())\n",
    "            operazioni_uniche.add(coppia)\n",
    "\n",
    "\n",
    "df_operazioni = pd.DataFrame(sorted(list(operazioni_uniche)), columns=[\"Codice Operazione\", \"Descrizione Operazione\"])\n",
    "\n",
    "# Ordina per Codice Operazione\n",
    "df_operazioni.sort_values(by=\"Codice Operazione\", inplace=True, ignore_index=True)\n",
    "\n",
    "output_path = os.path.join(cartella_input, \"Tabella_Operazioni.xlsx\")\n",
    "df_operazioni.to_excel(output_path, index=False)\n",
    "\n",
    "print(f\"\\n Tabella Operazioni creata correttamente in:\\n{output_path}\")\n",
    "print(f\" Totale operazioni trovate: {len(df_operazioni)}\\n\")\n",
    "print(df_operazioni.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "631980bd-11e3-4425-833e-80badebde408",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
